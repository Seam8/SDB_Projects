{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('C:/Users/samrari/ComputBuffer')\n",
    "from my_packages.My_Geoprocess import*\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure, img_as_float, morphology\n",
    "\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "import xml.etree.ElementTree as ET\n",
    "import os, fnmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper left corner :  (165.9735606070099, -22.692427357900442) \n",
      "Lower right corner :  (167.02786117314153, -21.691015824552036)\n"
     ]
    }
   ],
   "source": [
    "xml_filePath = \"C:/Users/samrari/ComputBuffer/Image/Sen2/S2A_MSIL1C_20170718T231141_N0205_R101_T58KFA_20170718T231219.SAFE/\"\n",
    "xml_fileName = \"MTD_MSIL1C.xml\"\n",
    "gdal.ErrorReset()\n",
    "ds = gdal.Open( xml_filePath + xml_fileName )\n",
    "\n",
    "if ds is None or gdal.GetLastErrorMsg() != '':\n",
    "    print('xml failed to load')\n",
    "    \n",
    "DataSet_md = ds.GetMetadata()\n",
    "SubDataSet_md = ds.GetMetadata('SUBDATASETS')\n",
    "\n",
    "ds = []\n",
    "# Try opening the 4 subdatasets\n",
    "for i in range(4):\n",
    "    gdal.ErrorReset()\n",
    "    ds.append(gdal.Open(SubDataSet_md['SUBDATASET_%d_NAME' % (i+1)]))\n",
    "    if ds is None or gdal.GetLastErrorMsg() != '':\n",
    "        print('subdatasets failed to load')\n",
    "        print(SubDataSet_md['SUBDATASET_%d_NAME' % (i+1)])\n",
    "src_ds = ds[0]\n",
    "ds[0].RasterCount\n",
    "\n",
    "# Define Raster Footprint\n",
    "\n",
    "RasterWidth = src_ds.RasterXSize\n",
    "RasterHeight = src_ds.RasterYSize\n",
    "GT_ds = src_ds.GetGeoTransform()\n",
    "min_x = GT_ds[0]\n",
    "min_y = GT_ds[3] + RasterWidth*GT_ds[4] + RasterHeight*GT_ds[5] \n",
    "max_x = GT_ds[0] + RasterWidth*GT_ds[1] + RasterHeight*GT_ds[2]\n",
    "max_y = GT_ds[3] \n",
    "\n",
    "srs_ds = osr.SpatialReference()\n",
    "srs_ds.ImportFromWkt(src_ds.GetProjection())\n",
    "\n",
    "srsLatLong = srs_ds.CloneGeogCS()\n",
    "ct_ds = osr.CoordinateTransformation(srs_ds,srsLatLong)\n",
    "\n",
    "min_E, min_N = ct_ds.TransformPoint(min_x, min_y)[:2]\n",
    "max_E, max_N = ct_ds.TransformPoint(max_x, max_y)[:2]\n",
    "\n",
    "print('Upper left corner : ', (min_E, min_N), '\\nLower right corner : ', (max_E, max_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RePath_xmlDirectory = 'Data_SHOM/Global'\n",
    "TimeThres = 1970\n",
    "\n",
    "Selected_xml, LoopCount, count = GetXml_byFootprint(RePath_xmlDirectory,(min_E, max_E), (min_N, max_N), FromYear=TimeThres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18468224, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Set , Count, failedXml = GetSurvey_byDepthFP(Selected_xml, RePath_xmlDirectory,(min_E, max_E), (min_N, max_N), max_Depth=10000)\n",
    "Set[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = ET.parse(RePath_xmlDirectory+'/'+'S201406300-1.object.xml').getroot()\n",
    "int(root.find('Attribute[@name=\"SURSTA\"]').find('Value').text[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordSurvey('CSV/SelectReleves.csv', Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recordPosition('CSV/SelectReleves_1970.csv', Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RePath_xmlDirectory = 'Data_SHOM/Global'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecordSurveyAndYear(XML_List, RePath_xmlDirectory, path_filname):\n",
    "    \n",
    "    with open(path_filname, 'w') as mon_fichier:\n",
    "        print('Date',';', 'Lon', ';', 'Lat', ';', 'Depth', file= mon_fichier)\n",
    "\n",
    "    for xml in XML_List:\n",
    "        # initilise\n",
    "        Set_Point = []\n",
    "        Set_Depth = []\n",
    "        Set_xml = []\n",
    "        countValidPT = []\n",
    "        NoValid_xml = []\n",
    "\n",
    "        # read current xml\n",
    "        DepthPt = pd.read_csv(RePath_xmlDirectory+'/'+xml[:-10]+'ascii', delim_whitespace=True, header=None, names=['Lat','Lon','Depth'])\n",
    "        # filter by depth\n",
    "        DepthPt_40m = DepthPt\n",
    "        # loads points\n",
    "        current_pt =  DepthPt_40m[['Lon','Lat']].values\n",
    "        current_depth =  DepthPt_40m['Depth'].values\n",
    "\n",
    "        # records points\n",
    "        Set_Point.extend(current_pt[:,:])\n",
    "        Set_Depth.extend(current_depth[:])\n",
    "        root = ET.parse(RePath_xmlDirectory+'/'+xml).getroot()\n",
    "        Set_xml.extend(np.tile((root.find('Attribute[@name=\"SURSTA\"]').find('Value').text),len(current_depth)))\n",
    "        countValidPT.append(len(current_depth))  \n",
    "\n",
    "        Set , Count, failedXml =  [np.asarray(Set_xml),  np.asarray(Set_Point), np.asarray(Set_Depth)], countValidPT, NoValid_xml\n",
    "\n",
    "        with open(path_filname, 'a+') as mon_fichier:\n",
    "            for i in range(len(Set[2])):\n",
    "                print(Set[0][i], ';', Set[1][i,0], ';', Set[1][i,1], ';', Set[2][i], file= mon_fichier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Selected_xml = []\n",
    "for xmlFile in GetFiles(\"*.xml\",directory=RePath_xmlDirectory, TimLim=1900):\n",
    "    Selected_xml.append(xmlFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RecordSurveyAndYear(Selected_xml, RePath_xmlDirectory, 'ShomSurveys.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordSurveyAndYear(Selected_xml[0:2], RePath_xmlDirectory, 'test.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
