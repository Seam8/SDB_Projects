{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import exposure, img_as_float, morphology, color\n",
    "from skimage.measure import label\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "import my_packages.My_Geoprocess as mgp\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Rasters Informations, size, Geotransform... following one of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10980 10980\n"
     ]
    }
   ],
   "source": [
    "ClassifFolder = '../../../Poe/Resultats/Classifications/'\n",
    "ImagesFolder = '../../../Poe/Images/Acolyte/S2A_MSIL1C_20180305T230901_N0206_R101_T58KEB_20180306T00234_bisAco/S2A_MSI_2018_03_05_23_09_01_T58KEB_L2R_tif/'\n",
    "raster_wavelength = ['560']\n",
    "raster_Name = ['rhos_' + l + '.tif' for l in raster_wavelength]\n",
    "\n",
    "src_ds = gdal.Open(ImagesFolder+raster_Name[0], gdal.GA_ReadOnly)\n",
    "band = src_ds.GetRasterBand(1)\n",
    "GT_ds = src_ds.GetGeoTransform()\n",
    "proj = src_ds.GetProjection()\n",
    "RasterHeight, RasterWidth = (src_ds.RasterYSize, src_ds.RasterXSize)\n",
    "print(RasterHeight, RasterWidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Rasters footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper left corner :  (164.99980652185837, -21.791778063706154) \n",
      "Lower right corner :  (166.0548316017674, -20.79645641405817)\n"
     ]
    }
   ],
   "source": [
    "# Define Raster Footprint\n",
    "min_x = GT_ds[0]\n",
    "min_y = GT_ds[3] + RasterWidth*GT_ds[4] + RasterHeight*GT_ds[5] \n",
    "max_x = GT_ds[0] + RasterWidth*GT_ds[1] + RasterHeight*GT_ds[2]\n",
    "max_y = GT_ds[3]   \n",
    "\n",
    "srs_ds = osr.SpatialReference()\n",
    "srs_ds.ImportFromWkt(src_ds.GetProjection())\n",
    "\n",
    "srsLatLong = srs_ds.CloneGeogCS()\n",
    "ct_ds = osr.CoordinateTransformation(srs_ds,srsLatLong)\n",
    "\n",
    "min_E, min_N = ct_ds.TransformPoint(min_x, min_y)[:2]\n",
    "max_E, max_N = ct_ds.TransformPoint(max_x, max_y)[:2]\n",
    "\n",
    "print('Upper left corner : ', (min_E, min_N), '\\nLower right corner : ', (max_E, max_N))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get surveyfiles (ascii), having measurement contained in rasters footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileWorkableSur = '../../Terrain/MesuresBathy/Poe_22and23_05_2018.txt'\n",
    "\n",
    "MeasurementFrame = pd.read_csv(FileWorkableSur)\n",
    "Lon = MeasurementFrame['Lon'].astype('float64').values\n",
    "Lat = MeasurementFrame['Lat'].astype('float64').values\n",
    "\n",
    "CoordinatesSet = np.stack([Lon,Lat], axis=1)\n",
    "depth = MeasurementFrame['Depth'].astype('float32').values\n",
    "\n",
    "del MeasurementFrame, Lon, Lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convert measurements coordinate in pixels coordinate (+ checking process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no int\n",
      "Center at Row: 10979.4685216 , Col: 10979.5091234\n",
      "UpperLeft at Row: 10979.0156563 , Col: 10979.0128596\n",
      "UpperRight at Row: 10979.0224421 , Col: 10979.999165\n",
      "LowerRight at Row: 10979.9899339 , Col: 10979.9925083\n",
      "PreviousNext at Row: 10979.444926 , Col: 10978.9757872\n",
      "no int\n",
      "Number of point with negative depth : 0\n"
     ]
    }
   ],
   "source": [
    "testLocation = np.array([[166.0618842, -21.7883184],\n",
    "                         [166.0618359, -21.7882778],\n",
    "                         [166.0619313, -21.7882778],\n",
    "                         [166.0619313, -21.7883652],\n",
    "                         [166.0618326, -21.7883166]])\n",
    "\n",
    "# Define pixel location of measured data\n",
    "ctInv = osr.CoordinateTransformation(srsLatLong, srs_ds)\n",
    "inv_geometrix = gdal.InvGeoTransform(GT_ds)\n",
    "(Cols, Rows) = mgp.GetPixel(ctInv, inv_geometrix, testLocation,integer=False)\n",
    "Location = ['Center', 'UpperLeft', 'UpperRight', 'LowerRight','PreviousNext']\n",
    "[print(Loc,'at Row:', row,', Col:', col) for Loc, col, row in zip(Location, Cols,Rows)]\n",
    "\n",
    "# Project coordinates in pixel coordinates then filter measured data projected outside image extent\n",
    "px, py = mgp.GetPixel(ctInv, inv_geometrix, CoordinatesSet,integer=False) # Case for dense field data, need interger=False for wheigtering or interpolation\n",
    "indexOut = np.logical_or(np.logical_or(py>RasterHeight-1,py<0), np.logical_or(px>RasterWidth-1,px<0))\n",
    "px, py = px[~indexOut], py[~indexOut]\n",
    "\n",
    "# Adjust water depth following the Tide at the image sensor Time\n",
    "TideHeight = 1.31 # Height of tide from SHOM website\n",
    "depth = depth[~indexOut]+TideHeight\n",
    "\n",
    "# filter measured data with negative depth (due to tide)\n",
    "indexOut = depth<0\n",
    "print('Number of point with negative depth :', np.sum(indexOut))\n",
    "px, py, depth = px[~indexOut], py[~indexOut], depth[~indexOut]\n",
    "assert px.shape==py.shape and px.shape == depth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workingIndex or Index of classification and bathymetry mapping\n",
    "###### In others words :        ClassifIndex = ~Soil x ~DeepOcean x CroppedImage\n",
    "######                                     ClassifIndex.shape == Initial_Rasters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980, 10980)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd556978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lagoon = 'Mask/Lagoon.tif'\n",
    "\n",
    "ClassifIndex = gdal.Open(ImagesFolder + Lagoon, gdal.GA_ReadOnly)\n",
    "ClassifIndex = ClassifIndex.GetRasterBand(1).ReadAsArray().astype(bool)\n",
    "print(ClassifIndex.shape)\n",
    "plt.imshow(ClassifIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index(SurveyIndex) indicating the presence of measurements in a pixel\n",
    "## Create dictionary(Dicto) of depths measured at a pixel location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sub (2d) index for measured pixel\n",
    "SurveyIndex = np.full(ClassifIndex.shape, 0, dtype=np.int8)\n",
    "DictoDeph = {}\n",
    "DictoPos = {}\n",
    "for i in range(len(px)):\n",
    "    Intpy, Intpx = int(py[i]),int(px[i])\n",
    "    try:\n",
    "        if ClassifIndex[Intpy, Intpx] == False: # Case for Poe int(px)\n",
    "            continue\n",
    "        SurveyIndex[Intpy, Intpx] += 1\n",
    "        if SurveyIndex[Intpy, Intpx] == 1:\n",
    "            DictoDeph[Intpy, Intpx] = []\n",
    "            DictoPos[Intpy, Intpx] = []\n",
    "            DictoDeph[Intpy, Intpx].append(depth[i])\n",
    "            DictoPos[Intpy, Intpx].append([py[i], px[i]])\n",
    "        else:\n",
    "            DictoDeph[Intpy, Intpx].append(depth[i])\n",
    "            DictoPos[Intpy, Intpx].append([py[i], px[i]])\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Statistics on pixels containing measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SurveyRatio = np.full(ClassifIndex.shape, np.NaN, dtype= np.float_)\n",
    "SurveyDisposition = {}\n",
    "for i, j  in DictoDeph.keys():\n",
    "    assert len(DictoPos[(i, j)]) == len(DictoDeph[(i, j)])\n",
    "    Points = np.asarray(DictoPos[(i, j)])\n",
    "    SurveyRatio[i, j], SurveyDisposition[i, j] = mgp.get_OccupiedRatio(Points[:,0], Points[:,1], radius=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(SurveyRatio[~np.isnan(SurveyRatio)], 50, histtype='step', cumulative=1, normed=True)\n",
    "plt.xlabel('Occupied ratio in pixels')\n",
    "plt.ylabel('Frequence')\n",
    "plt.title('Cumulative hitograme or area occupied in pixels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoverThreshold = 0.20\n",
    "print('Nombre de Pixels Totale : {0:d}\\nNombre de Pixels conservé: {1:d}'.format(np.sum(~np.isnan(SurveyRatio)),np.sum(SurveyRatio>CoverThreshold))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurveyValues = np.full(ClassifIndex.shape, np.NaN, dtype= np.float_)\n",
    "SurveyIndex = np.full(ClassifIndex.shape, False, dtype=np.bool_)\n",
    "\n",
    "rows, cols = np.where(SurveyRatio>CoverThreshold)\n",
    "for i, j  in zip(rows,cols):\n",
    "    Points = np.asarray(DictoPos[(i, j)])\n",
    "    SurveyValues[i, j] = mgp.InterpPixDepth(Points, DictoDeph[i, j], modes=['nearest'], PlotArg=False)[0]\n",
    "    SurveyIndex[i, j] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optical Data\n",
    "### WARNING: Poe special case -> to avoid bigger backup size, data need to be resize at Rasters dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data at reduce backup size\n",
    "npzfile = np.load('../../../Poe/CompressedData/SRXData.npz')\n",
    "Xc = npzfile['Ratios'] # Optical data at croped shape (reduce backup size)\n",
    "RatiosKeys = npzfile['Keys'] # Keys defining order of recorded ratios \n",
    "\n",
    "# Creation of arrays at Raster Size\n",
    "X = np.full((RasterHeight, RasterWidth, Xc.shape[2]), np.nan) # Final array of optical data at Raster size \n",
    "ValidMap = np.full((RasterHeight, RasterWidth), False) # Map of area of Interest -> cropped area reducing backup size\n",
    "\n",
    "# Translation of the data at the suitable dimension\n",
    "X[5000:,0:8500,:] = Xc[:,:,:]\n",
    "ValidMap[5000:,0:8500] = True\n",
    "del Xc\n",
    "\n",
    "# Useless here...\n",
    "ToclassifyIndex = np.logical_and(ValidMap,ClassifIndex)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special case in Poe, Area of interest for specific calibration manually created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeFolder = '../../../Poe/Shapes/'\n",
    "RoiPathName = 'SheratonLagoon.shp'\n",
    "\n",
    "ResctictedLagoon = mgp.create_mask_from_vector(ShapeFolder + RoiPathName,  RasterHeight, RasterWidth, GT_ds, proj, target_value=1, format=gdal.GDT_Byte)\n",
    "ResctictedLagoon = ResctictedLagoon.GetRasterBand(1).ReadAsArray().astype(bool)\n",
    "plt.imshow(ResctictedLagoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual check !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manual cropping for better visual rendering\n",
    "ScatterIndex = np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650])\n",
    "CroppedDepth = SurveyValues[8800:9400,3500:4650] # Average deph of pixels contained in the visual cropped\n",
    "\n",
    "# Scatter coordinates and image in rendered dimension\n",
    "x,y = np.where(ScatterIndex)\n",
    "Im = ResctictedLagoon[8800:9400,3500:4650]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(50,50))\n",
    "plt.imshow(Im)\n",
    "plt.scatter(y,x,s=80, c='r')\n",
    "for i in range(len(x)):\n",
    "    ax.annotate('{0:.2f}'.format(CroppedDepth[ScatterIndex][i]), (y[i]-10,x[i]+10), color='red', size=20)\n",
    "print(\"Nombre de pixel comportant une mesure immergées:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X.shape[:2]==SurveyValues.shape\n",
    "ind = ResctictedLagoon * (SurveyIndex>0) # Index of calibration data\n",
    "Data_x = X[ind,:] # model optical descriptors\n",
    "Data_y = SurveyValues[ind].reshape(np.sum(ind),) # model target depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploratory statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Data_x.shape[1]):\n",
    "    print(str(RatiosKeys[i]),'correlation : ',np.corrcoef(Data_x[:,i],Data_y)[0,1])\n",
    "    print(\"=\"*10)\n",
    "mgp.plot_ResRegPlots(Data_x, Data_y, Scale=True, SetTitles=True, Titles=[str(i)+'/'+str(j) for i,j in RatiosKeys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(20, 8))\n",
    "fig.suptitle('Scatters Plot')\n",
    "fig.subplots_adjust(hspace=.5, top=.88)\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.scatter(Data_x[:,i],Data_y, s=4)\n",
    "    ax.set_title(RatiosKeys[i][0]+'/'+RatiosKeys[i][1]+'\\nCorrelation: {0:0.2f}'.format(np.corrcoef(Data_x[:,i],Data_y)[0,1]))\n",
    "    ax.set_ylabel('Depth')\n",
    "    ax.set_xlabel('Optical Signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Data_x\n",
    "y = Data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear Regression (Stumpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotsPerRows = 3\n",
    "fig , axes = plt.subplots(int(np.ceil(x.shape[1]/plotsPerRows)),plotsPerRows, figsize=(15,18))\n",
    "fig.suptitle('Simple crossvalidated Linear regression (Stumpf)')\n",
    "fig.subplots_adjust(hspace=.5, top=.9)\n",
    "Outputs = []\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    if i >= x.shape[1]:\n",
    "        ax.set_visible(False)\n",
    "        continue\n",
    "    Outputs.append(mgp.my_LeaveOneOutCV(linear_model.LinearRegression(), x[:,i].reshape(-1,1), y, ax=ax, SetTitles= True, Titles=RatiosKeys[i][0]+'/'+RatiosKeys[i][1]))\n",
    "    ax.set_xlim(1,4)\n",
    "    ax.set_ylim(1,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Multi-linear Regression (Stumpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outputs = []\n",
    "\n",
    "Outputs.append(mgp.my_LeaveOneOutCV(linear_model.LinearRegression(), x, y,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-linear : Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "Outputs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lr = linear_model.Ridge(alpha=a)\n",
    "    Outputs.append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=False))\n",
    "\n",
    "coefs = [Outputs[i][1]['Coefs'] for i in range(len(alphas))]\n",
    "RMS = [Outputs[i][1]['RMS'] for i in range(len(alphas))]\n",
    "R2_scores = [Outputs[i][1]['R2_score'] for i in range(len(alphas))]\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(nrows=1, ncols= 2, figsize=(20, 6))\n",
    "\n",
    "ax[0].plot(alphas, coefs)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Alpha')\n",
    "ax[0].set_ylabel('Weights')\n",
    "ax[0].set_title('Ridge coefficients as a function of the regularization')\n",
    "ax[0].axis('tight')\n",
    "ax[0].legend(labels=[str(i)+'/'+str(j) for i,j in RatiosKeys] )\n",
    "ax[1].plot(alphas, RMS)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Alpha')\n",
    "ax[1].set_ylabel('RMS')\n",
    "ax[1].set_title('Coefficient error as a function of the regularization')\n",
    "ax[1].axis('tight')\n",
    "\n",
    "fig.show\n",
    "\n",
    "print('Best RMS : {0:.3f} with alpha = {1:1.2E}\\nBest R2 : {2:.3f} with alpha = {3:1.2E}\\n'.format(\n",
    "np.min(RMS), alphas[np.argmin(RMS)], np.max(R2_scores), alphas[np.argmax(R2_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alphas[np.argmin(RMS)]\n",
    "lr = linear_model.Ridge(alpha=a)\n",
    "Outputs.append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-linear : Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "Outputs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lr = linear_model.Lasso(alpha=a, max_iter=10000)\n",
    "    Outputs.append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=False))\n",
    "\n",
    "coefs = [Outputs[i][1]['Coefs'] for i in range(len(alphas))]\n",
    "RMS = [Outputs[i][1]['RMS'] for i in range(len(alphas))]\n",
    "R2_scores = [Outputs[i][1]['R2_score'] for i in range(len(alphas))]\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(nrows=1, ncols= 2, figsize=(20, 6))\n",
    "\n",
    "ax[0].plot(alphas, coefs)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Alpha')\n",
    "ax[0].set_ylabel('Weights')\n",
    "ax[0].set_title('Lasso coefficients as a function of the regularization')\n",
    "ax[0].axis('tight')\n",
    "ax[0].legend(labels=[str(i)+'/'+str(j) for i,j in RatiosKeys] )\n",
    "ax[0].grid()\n",
    "ax[1].plot(alphas, RMS)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Alpha')\n",
    "ax[1].set_ylabel('RMS')\n",
    "ax[1].set_title('Coefficient error as a function of the regularization')\n",
    "ax[1].axis('tight')\n",
    "ax[1].grid()\n",
    "\n",
    "fig.show\n",
    "\n",
    "print('Best RMS : {0:.3f} with alpha = {1:1.2}\\nBest R2 : {2:.3f} with alpha = {3:1.2E}\\n'.format(\n",
    "np.min(RMS), alphas[np.argmin(RMS)], np.max(R2_scores), alphas[np.argmax(R2_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alphas[np.argmin(RMS)]\n",
    "lr = linear_model.Lasso(alpha=a, max_iter=10000)\n",
    "Outputs.append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SizeE, SizeA = 10, 10\n",
    "epsilons = np.linspace(1.01, 1.40, SizeE)\n",
    "alphas = np.logspace(-6, 6, SizeA)\n",
    "RMS = np.full((SizeE,SizeA), np.nan, np.float)\n",
    "R2_scores = np.full((SizeE,SizeA), np.nan, np.float)\n",
    "coefs = np.full((SizeE,SizeA,x.shape[1]), np.nan, np.float)\n",
    "\n",
    "Outputs = []\n",
    "\n",
    "for ie, e in enumerate(epsilons):\n",
    "    Outputs.append([])\n",
    "    for ia, a in enumerate(alphas):\n",
    "        lr = linear_model.HuberRegressor(alpha=a, epsilon=e, fit_intercept=True, max_iter=1000)\n",
    "        Outputs[ie].append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=False))\n",
    "    RMS[ie,:] = np.asarray([Outputs[ie][i][1]['RMS'] for i in range(len(alphas))])\n",
    "    R2_scores[ie,:] = np.asarray([Outputs[ie][i][1]['R2_score'] for i in range(len(alphas))])\n",
    "    coefs[ie,:,:] = np.asarray([Outputs[ie][i][1]['Coefs'] for i in range(len(alphas))])\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(nrows=1, ncols= 2, figsize=(20, 6))\n",
    "\n",
    "ax[0].imshow(RMS)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Alphas')\n",
    "ax[0].set_ylabel('Epsilons')\n",
    "ax[0].set_title('Huber Regression: Root Mean Square as funtion of Alphas, Epsilons')\n",
    "ax[0].axis('tight')\n",
    "\n",
    "ax[1].imshow(R2_scores)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Alphas')\n",
    "ax[1].set_ylabel('Epsilons')\n",
    "ax[1].set_title('Huber Regression: Root Mean Square as funtion of Alphas, Epsilons')\n",
    "ax[1].axis('tight')\n",
    "fig.show\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(nrows=1, ncols= 2, figsize=(20, 6))\n",
    "\n",
    "ax[0].plot(alphas, coefs)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Alpha')\n",
    "ax[0].set_ylabel('Weights')\n",
    "ax[0].set_title('Ridge coefficients as a function of the regularization')\n",
    "ax[0].axis('tight')\n",
    "ax[0].legend(labels=[str(i)+'/'+str(j) for i,j in RatiosKeys] )\n",
    "ax[0].grid()\n",
    "ax[1].plot(alphas, RMS)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Alpha')\n",
    "ax[1].set_ylabel('RMS')\n",
    "ax[1].set_title('Coefficient error as a function of the regularization')\n",
    "ax[1].axis('tight')\n",
    "ax[1].grid()\n",
    "fig.show\n",
    "\n",
    "print('Best RMS : {0:.3f} with alpha = {1:1.2E}\\nBest R2 : {2:.3f} with alpha = {3:1.2E}\\n'.format(\n",
    "np.min(RMS), alphas[np.argmin(RMS)], np.max(R2_scores), alphas[np.argmax(R2_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "X, Y = np.meshgrid(epsilons, alphas)\n",
    "ax.set_ylabel('Epsilons')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Alpha')\n",
    "ax.set_zlabel('RMS')\n",
    "surf = ax.plot_surface(X, Y, RMS, cmap=cm.coolwarm,linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alphas[np.argmin(RMS)]\n",
    "lr = linear_model.HuberRegressor(alpha=a, max_iter=10000)\n",
    "Outputs.append(mgp.my_LeaveOneOutCV(lr, x, y, DoPlot=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.RidgeCV(cv=115,fit_intercept=True, alphas= (10 ,0.1))\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)\n",
    "ax.scatter(y, predicted, s=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Crossvalidated Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "#predicted = cross_val_predict(lr, x, y, cv=len(y))\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validated RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x)\n",
    "predicted = np.full(y.shape,np.nan, np.float)\n",
    "inlierMat = np.full((y.shape[0], 1, len(y)),np.nan, np.float)\n",
    "#lr = linear_model.RANSACRegressor(min_samples=0.9, max_trials=100000, residual_threshold=0.4,stop_probability=0.999)\n",
    "lr = linear_model.RANSACRegressor(min_samples=0.5, residual_threshold=0.2)\n",
    "counterCheck = 0\n",
    "\n",
    "\n",
    "for train_index, test_index in loo.split(x):\n",
    "    lr.fit(x[train_index], y[train_index])\n",
    "    predicted[test_index] = lr.predict(x[test_index])\n",
    "    inlierMat[train_index, 0, counterCheck] = lr.inlier_mask_\n",
    "    counterCheck = counterCheck + 1\n",
    "    \n",
    "col = np.nansum(inlierMat, axis=2)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "im = ax.scatter(y, predicted,c=col, cmap='jet')\n",
    "plt.colorbar(im)\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xIm,yIm = np.where(np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0))\n",
    "y = SurveyValues[ind].reshape(np.sum(ind),)\n",
    "plotInd = (col>5).reshape(len(y),)\n",
    "indIm = ResctictedLagoon[8800:9400,3500:4650]\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plt.imshow(indIm)\n",
    "plt.scatter(yIm[plotInd],xIm[plotInd],s=80, c='b', label='Inliers')\n",
    "plt.scatter(yIm[~plotInd],xIm[~plotInd],s=80, c='r', label='Outliers')\n",
    "plt.legend()\n",
    "print(\"Nombre de point extreme :\",np.sum(~plotInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[train_index].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x)\n",
    "predicted = np.full(y.shape,np.nan, np.float)\n",
    "lr = linear_model.TheilSenRegressor()\n",
    "counterCheck = 0\n",
    "\n",
    "for train_index, test_index in loo.split(x):\n",
    "    lr.fit(x[train_index], y[train_index])\n",
    "    predicted[test_index] = lr.predict(x[test_index])\n",
    "    counterCheck = counterCheck + 1\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "im = ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAC Whithout cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.RANSACRegressor(min_samples=0.9, max_trials=100000, residual_threshold=0.4,stop_probability=0.999)\n",
    "\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)\n",
    "ax.scatter(y, predicted, c=lr.inlier_mask_, s=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xIm,yIm = np.where(np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0))\n",
    "y = SurveyValues[ind].reshape(np.sum(ind),)\n",
    "plotInd = (col>5).reshape(len(y),)\n",
    "indIm = ResctictedLagoon[8800:9400,3500:4650]\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plt.imshow(indIm)\n",
    "plt.scatter(yIm[plotInd],xIm[plotInd],s=80, c='b', label='Inliers')\n",
    "plt.scatter(yIm[~plotInd],xIm[~plotInd],s=80, c='r', label='Outliers')\n",
    "plt.legend()\n",
    "print(\"Nombre de point extreme :\",np.sum(~plotInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = testImage[8800:9400,3500:4650]**0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xIm,yIm = np.where(np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0))\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plt.imshow(testImage)\n",
    "plt.scatter(yIm,xIm,s=80, c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
