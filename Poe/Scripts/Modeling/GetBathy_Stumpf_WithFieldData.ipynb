{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import exposure, img_as_float, morphology, color\n",
    "from skimage.measure import label\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "import my_packages.My_Geoprocess as mgp\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Rasters Informations, size, Geotransform... following one of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassifFolder = '../../../Poe/Resultats/Classifications/'\n",
    "ImagesFolder = '../../../Poe/Images/Acolyte/S2A_MSIL1C_20180305T230901_N0206_R101_T58KEB_20180306T00234_bisAco/S2A_MSI_2018_03_05_23_09_01_T58KEB_L2R_tif/'\n",
    "raster_wavelength = ['560']\n",
    "raster_Name = ['rhos_' + l + '.tif' for l in raster_wavelength]\n",
    "\n",
    "src_ds = gdal.Open(ImagesFolder+raster_Name[0], gdal.GA_ReadOnly)\n",
    "band = src_ds.GetRasterBand(1)\n",
    "GT_ds = src_ds.GetGeoTransform()\n",
    "proj = src_ds.GetProjection()\n",
    "RasterHeight, RasterWidth = (src_ds.RasterYSize, src_ds.RasterXSize)\n",
    "print(RasterHeight, RasterWidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Rasters footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Raster Footprint\n",
    "min_x = GT_ds[0]\n",
    "min_y = GT_ds[3] + RasterWidth*GT_ds[4] + RasterHeight*GT_ds[5] \n",
    "max_x = GT_ds[0] + RasterWidth*GT_ds[1] + RasterHeight*GT_ds[2]\n",
    "max_y = GT_ds[3]   \n",
    "\n",
    "srs_ds = osr.SpatialReference()\n",
    "srs_ds.ImportFromWkt(src_ds.GetProjection())\n",
    "\n",
    "srsLatLong = srs_ds.CloneGeogCS()\n",
    "ct_ds = osr.CoordinateTransformation(srs_ds,srsLatLong)\n",
    "\n",
    "min_E, min_N = ct_ds.TransformPoint(min_x, min_y)[:2]\n",
    "max_E, max_N = ct_ds.TransformPoint(max_x, max_y)[:2]\n",
    "\n",
    "print('Upper left corner : ', (min_E, min_N), '\\nLower right corner : ', (max_E, max_N))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get surveyfiles (ascii), having measurement contained in rasters footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileWorkableSur = '../../Terrain/MesuresBathy/Poe_22and23_05_2018.txt'\n",
    "\n",
    "MeasurementFrame = pd.read_csv(FileWorkableSur)\n",
    "MeasurementFrame[' Lon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select xml datafiles following common extent\n",
    "RePath_xmlDirectory = '../../../Data_SHOM/Global'\n",
    "TimeThres = 1950\n",
    "#%timeit mgp.GetXml_byFootprint(RePath_xmlDirectory,(min_E, max_E), (min_N, max_N))\n",
    "#%timeit mgp.GetXml_byFootprint2(RePath_xmlDirectory, min_E, max_E, min_N, max_N)\n",
    "Selected_xml, LoopCount, count = mgp.GetXml_byFootprint(RePath_xmlDirectory,(min_E, max_E), (min_N, max_N), FromYear=TimeThres)\n",
    "print('Selected_xml :')\n",
    "[print(xml) for xml in Selected_xml]\n",
    "# Select xml datafiles following maximum depth\n",
    "Upto = 20\n",
    "Set , Count, failedXml = mgp.GetSurvey_byDepthFP(Selected_xml, RePath_xmlDirectory,(min_E, max_E), (min_N, max_N), max_Depth=Upto)\n",
    "assert np.sum(Count) == Set[1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convert measurements coordinate in pixels coordinate (+ checking process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLocation = np.array([[166.0618842, -21.7883184],\n",
    "                         [166.0618359, -21.7882778],\n",
    "                         [166.0619313, -21.7883652],\n",
    "                         [166.0618326, -21.7883166]])\n",
    "\n",
    "# Define pixel location of measured data\n",
    "ctInv = osr.CoordinateTransformation(srsLatLong, srs_ds)\n",
    "inv_geometrix = gdal.InvGeoTransform(GT_ds)\n",
    "(Px, Py) = mgp.GetPixel(ctInv, inv_geometrix, testLocation,integer=False)\n",
    "Location = ['Center', 'UpperLeft', 'LowerRight','PreviousNext']\n",
    "[print(Loc, pxx, pyy) for Loc, pxx, pyy in zip(Location, Px,Py)]\n",
    "\n",
    "# Project coordinates in pixel coordinates then filter measured data projected outside image extent\n",
    "px, py = mgp.GetPixel(ctInv, inv_geometrix, Set[1])\n",
    "indexOut = np.logical_or(np.logical_or(py>RasterHeight-1,py<0), np.logical_or(px>RasterWidth-1,px<0))\n",
    "px, py = px[~indexOut], py[~indexOut]\n",
    "\n",
    "# Adjust water depth following the Tide at the image sensor Time\n",
    "TideHeight = 1.31 # Height of tide from SHOM website\n",
    "depth=Set[2][~indexOut]+TideHeight\n",
    "\n",
    "# filter measured data with negative depth (due to tide)\n",
    "indexOut = depth<0\n",
    "print('Number of point with negative depth :', np.sum(indexOut))\n",
    "px, py, depth = px[~indexOut], py[~indexOut], depth[~indexOut]\n",
    "assert px.shape==py.shape and px.shape == depth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workingIndex or Index of classification and bathymetry mapping\n",
    "###### In others words :        ClassifIndex = ~Soil x ~DeepOcean x CroppedImage\n",
    "######                                     ClassifIndex.shape == Initial_Rasters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagoon = 'Mask/Lagoon.tif'\n",
    "\n",
    "ClassifIndex = gdal.Open(ImagesFolder + Lagoon, gdal.GA_ReadOnly)\n",
    "ClassifIndex = ClassifIndex.GetRasterBand(1).ReadAsArray().astype(bool)\n",
    "print(ClassifIndex.shape)\n",
    "plt.imshow(ClassifIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index(SurveyIndex) indicating the presence of measurements in a pixel\n",
    "## Create dictionary(Dicto) of depths measured at a pixel location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create sub (2d) index for measured pixel\n",
    "SurveyIndex = np.full(ClassifIndex.shape, 0, dtype=np.int8)\n",
    "Dicto = {}\n",
    "for i in range(len(px)):\n",
    "    try:\n",
    "        if ClassifIndex[py[i],px[i]] == False:\n",
    "            continue\n",
    "        SurveyIndex[py[i],px[i]] += 1\n",
    "        if SurveyIndex[py[i],px[i]] == 1:\n",
    "            Dicto[(py[i],px[i])] = [depth[i]]\n",
    "        else:\n",
    "            Dicto[(py[i],px[i])].append(depth[i])\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Statistics on pixels containing measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SurveyValues = np.full(ClassifIndex.shape, np.NaN, dtype= np.float_)\n",
    "SurveyVariance = np.full(ClassifIndex.shape, np.NaN, dtype= np.float_)\n",
    "for i, j  in Dicto.keys():\n",
    "    SurveyValues[i, j] = np.mean(Dicto[(i, j)])\n",
    "    SurveyVariance[i, j] = np.std(Dicto[(i, j)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optical Data\n",
    "### WARNING: Poe special case -> to avoid bigger backup size, data need to be resize at Rasters dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data at reduce backup size\n",
    "npzfile = np.load('../../../Poe/CompressedData/SRXData.npz')\n",
    "Xc = npzfile['Ratios'] # Optical data at croped shape (reduce backup size)\n",
    "RatiosKeys = npzfile['Keys'] # Keys defining order of recorded ratios \n",
    "\n",
    "# Creation of arrays at Raster Size\n",
    "X = np.full((RasterHeight, RasterWidth, Xc.shape[2]), np.nan) # Final array of optical data at Raster size \n",
    "ValidMap = np.full((RasterHeight, RasterWidth), False) # Map of area of Interest -> cropped area reducing backup size\n",
    "\n",
    "# Translation of the data at the suitable dimension\n",
    "X[5000:,0:8500,:] = Xc[:,:,:]\n",
    "ValidMap[5000:,0:8500] = True\n",
    "del Xc\n",
    "\n",
    "# Useless here...\n",
    "ToclassifyIndex = np.logical_and(ValidMap,ClassifIndex)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special case in Poe, Area of interest for specific calibration manually created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeFolder = '../../../Poe/Shapes/'\n",
    "RoiPathName = 'SheratonLagoon.shp'\n",
    "\n",
    "ResctictedLagoon = mgp.create_mask_from_vector(ShapeFolder + RoiPathName,  RasterHeight, RasterWidth, GT_ds, proj, target_value=1, format=gdal.GDT_Byte)\n",
    "ResctictedLagoon = ResctictedLagoon.GetRasterBand(1).ReadAsArray().astype(bool)\n",
    "plt.imshow(ResctictedLagoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual check !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manual cropping for better visual rendering\n",
    "ScatterIndex = np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0)\n",
    "CroppedDepth = SurveyValues[8800:9400,3500:4650] # Average deph of pixels contained in the visual cropped\n",
    "\n",
    "# Scatter coordinates and image in rendered dimension\n",
    "x,y = np.where(ScatterIndex)\n",
    "Im = ResctictedLagoon[8800:9400,3500:4650]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(50,50))\n",
    "plt.imshow(Im)\n",
    "plt.scatter(y,x,s=80, c='r')\n",
    "for i in range(len(x)):\n",
    "    ax.annotate(CroppedDepth[ScatterIndex][i], (y[i]-10,x[i]+10), color='red', size=20)\n",
    "print(\"Nombre de pixel comportant une mesure immergées:\",len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of calibration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X.shape[:2]==SurveyValues.shape\n",
    "ind = ResctictedLagoon * (SurveyIndex>0) # Index of calibration data\n",
    "Data_x = X[ind,:] # model optical descriptors\n",
    "Data_y = SurveyValues[ind].reshape(np.sum(ind),) # model target depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploratory statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Data_x.shape[1]):\n",
    "    print(str(RatiosKeys[i]),'correlation : ',np.corrcoef(Data_x[:,i],Data_y)[0,1])\n",
    "    print(\"=\"*10)\n",
    "mgp.plot_ResRegPlots(Data_x, Data_y, Scale=True, SetTitles=False, Titles=RatiosKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(20, 8))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.scatter(Data_x[:,i],Data_y, s=4)\n",
    "    ax.set_title('Band  ' + str(RatiosKeys[i]))\n",
    "    ax.set_ylabel('Depth')\n",
    "    ax.set_xlabel('Optical Signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Data_x\n",
    "y = Data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "used_x = Data_x[:,1].reshape(len(y),)\n",
    "plt.scatter(used_x,y)\n",
    "buffer = np.array(stats.linregress(used_x,y)[:])\n",
    "Interval = np.array([np.min(x),np.max(x)])\n",
    "plt.plot(Interval, Interval*buffer[0]+buffer[1], c='k')\n",
    "plt.xlabel('Optical Signal')\n",
    "plt.ylabel('predicted Depth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = linear_model.RidgeCV(cv=115,fit_intercept=True, alphas= (10 ,0.1))\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)\n",
    "ax.scatter(y, predicted, s=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Crossvalidated Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "#predicted = cross_val_predict(lr, x, y, cv=len(y))\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validated RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x)\n",
    "predicted = np.full(y.shape,np.nan, np.float)\n",
    "inlierMat = np.full((y.shape[0], 1, len(y)),np.nan, np.float)\n",
    "#lr = linear_model.RANSACRegressor(min_samples=0.9, max_trials=100000, residual_threshold=0.4,stop_probability=0.999)\n",
    "lr = linear_model.RANSACRegressor(min_samples=0.5, residual_threshold=0.2)\n",
    "counterCheck = 0\n",
    "\n",
    "\n",
    "for train_index, test_index in loo.split(x):\n",
    "    lr.fit(x[train_index], y[train_index])\n",
    "    predicted[test_index] = lr.predict(x[test_index])\n",
    "    inlierMat[train_index, 0, counterCheck] = lr.inlier_mask_\n",
    "    counterCheck = counterCheck + 1\n",
    "    \n",
    "col = np.nansum(inlierMat, axis=2)\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "im = ax.scatter(y, predicted,c=col, cmap='jet')\n",
    "plt.colorbar(im)\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('R2 : '+str(r2_score(y, predicted)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(x)\n",
    "predicted = np.full(y.shape,np.nan, np.float)\n",
    "lr = linear_model.TheilSenRegressor()\n",
    "counterCheck = 0\n",
    "\n",
    "for train_index, test_index in loo.split(x):\n",
    "    lr.fit(x[train_index], y[train_index])\n",
    "    predicted[test_index] = lr.predict(x[test_index])\n",
    "    counterCheck = counterCheck + 1\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "im = ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAC Whithout cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = linear_model.RANSACRegressor(min_samples=0.9, max_trials=100000, residual_threshold=0.4,stop_probability=0.999)\n",
    "\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "predicted = lr.fit(x, y).predict(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)\n",
    "ax.scatter(y, predicted, c=lr.inlier_mask_, s=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xIm,yIm = np.where(np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0))\n",
    "y = SurveyValues[ind].reshape(np.sum(ind),)\n",
    "plotInd = (col>5).reshape(len(y),)\n",
    "ind = ResctictedLagoon[8800:9400,3500:4650]\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plt.imshow(ind)\n",
    "plt.scatter(yIm[plotInd],xIm[plotInd],s=80, c='b')\n",
    "plt.scatter(yIm[~plotInd],xIm[~plotInd],s=80, c='r')\n",
    "print(\"Nombre de point extreme :\",np.sum(~plotInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testImage = testImage[8800:9400,3500:4650]**0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xIm,yIm = np.where(np.logical_and(ResctictedLagoon[8800:9400,3500:4650],SurveyIndex[8800:9400,3500:4650]>0))\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "plt.imshow(testImage)\n",
    "plt.scatter(yIm,xIm,s=80, c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
